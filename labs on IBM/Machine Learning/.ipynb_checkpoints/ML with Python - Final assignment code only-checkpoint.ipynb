{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f015c8cf",
   "metadata": {},
   "source": [
    "# Classification with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f50d82",
   "metadata": {},
   "source": [
    "In this notebook we try to practice all the classification algorithms that we learned in this course.\n",
    "\n",
    "We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11630c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e3bb9e1",
   "metadata": {},
   "source": [
    "### About dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9575c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "This dataset is about past loans. The Loan_train.csv data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5f2dcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets download the dataset\n",
    "\n",
    "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff8ab1c7",
   "metadata": {},
   "source": [
    "### Load Data From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd84a6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a6a934",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d6b305",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['effective_date'] = pd.to_datetime(df['effective_date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b65f31b",
   "metadata": {},
   "source": [
    "## Data visualization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83762f97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s see how many of each class is in our data set\n",
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8353e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "bins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613d869",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(df.age.min(), df.age.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'age', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d76bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "854e9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at the day of the week people get the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "274b883d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = df['effective_date'].dt.dayofweek\n",
    "bins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e34a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that people who get the loan at the end of the week don't pay it off, so let's use Feature binarization to set a threshold value less than day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f32106",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf81b8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical features to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3374dac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's look at gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222eeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfecf847",
   "metadata": {},
   "outputs": [],
   "source": [
    "86 % of female pay there loans while only 73 % of males pay there loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4f0af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's convert male to 0 and female to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d981671",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c9c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "#### How about education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff7ab5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13be6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Features before One Hot Encoding\n",
    "df[['Principal','terms','age','Gender','education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eaec2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044027ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = df[['Principal','terms','age','Gender','weekend']]\n",
    "Feature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\n",
    "Feature.drop(['Master or Above'], axis = 1,inplace=True)\n",
    "Feature.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23984859",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Selection\n",
    "X = Feature\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846c1a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['loan_status'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07f839d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06607b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Standardization give data zero mean and unit variance (technically should be done after train test split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa0084d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c49377d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e13cbf89",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\n",
    "You should use the following algorithm:\n",
    "\n",
    "*   K Nearest Neighbor(KNN)\n",
    "*   Decision Tree\n",
    "*   Support Vector Machine\n",
    "*   Logistic Regression\n",
    "\n",
    "\\__ Notice:\\__\n",
    "\n",
    "*   You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n",
    "*   You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n",
    "*   You should include the code of the algorithm in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670f5576",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c801fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbor(KNN)\n",
    "\n",
    "Notice: You should find the best k to build the model with the best accuracy.\\\n",
    "**warning:** You should not use the **loan_test.csv** for finding the best k, however, you can split your train_loan.csv into train and test to find the best **k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fc00498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12211cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "k = 3\n",
    "#Train Model and Predict  \n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "kNN_model\n",
    "knn_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573ae3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best k\n",
    "Ks=15\n",
    "mean_acc=np.zeros((Ks-1))\n",
    "std_acc=np.zeros((Ks-1))\n",
    "ConfustionMx=[];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    kNN_model = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    yhat = kNN_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mean_acc[n-1]=np.mean(yhat==y_test);\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b2bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model again, using k=5\n",
    "k = 5\n",
    "#Train Model and Predict  \n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "kNN_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868895a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1028de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ccfdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "for d in range(1,10):\n",
    "    dt = DecisionTreeClassifier(criterion = 'entropy', max_depth = d).fit(X_train, y_train)\n",
    "    dt_yhat = dt.predict(X_test)\n",
    "    print(\"For depth = {}  the accuracy score is {} \".format(d, accuracy_score(y_test, dt_yhat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aea8d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Creating the best model for decision tree with best value of depth 1\n",
    "\n",
    "best_dt_model = DecisionTreeClassifier(criterion = 'entropy', max_depth = 1).fit(X_train, y_train)\n",
    "best_dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbd992",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bbf3460",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ef97d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
