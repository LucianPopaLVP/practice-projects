{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfc1bc02",
   "metadata": {},
   "source": [
    "# Classification with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed26f59",
   "metadata": {},
   "source": [
    "In this notebook we try to practice all the classification algorithms that we learned in this course.\n",
    "\n",
    "We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6474ff9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b0e0cb",
   "metadata": {},
   "source": [
    "### About dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336a3b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "This dataset is about past loans. The Loan_train.csv data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8ff835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets download the dataset\n",
    "\n",
    "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd19ae1",
   "metadata": {},
   "source": [
    "### Load Data From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd244d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d96011",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67fe322",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['effective_date'] = pd.to_datetime(df['effective_date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae46f2f7",
   "metadata": {},
   "source": [
    "## Data visualization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f8ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s see how many of each class is in our data set\n",
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47597e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "bins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2a0db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(df.age.min(), df.age.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'age', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b5d4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2fe096",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at the day of the week people get the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0d7aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = df['effective_date'].dt.dayofweek\n",
    "bins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f485d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that people who get the loan at the end of the week don't pay it off, so let's use Feature binarization to set a threshold value less than day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa3a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b68bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical features to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02afc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's look at gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d7bed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cb5600",
   "metadata": {},
   "outputs": [],
   "source": [
    "86 % of female pay there loans while only 73 % of males pay there loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727bc301",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's convert male to 0 and female to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db1bf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d16e6641",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "#### How about education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2255f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f960f29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Features before One Hot Encoding\n",
    "df[['Principal','terms','age','Gender','education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bc4502",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33e1230",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = df[['Principal','terms','age','Gender','weekend']]\n",
    "Feature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\n",
    "Feature.drop(['Master or Above'], axis = 1,inplace=True)\n",
    "Feature.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a103d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Selection\n",
    "X = Feature\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3e8518",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['loan_status'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ce388fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fca784",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Standardization give data zero mean and unit variance (technically should be done after train test split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb633193",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "332c7590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bf3ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\n",
    "You should use the following algorithm:\n",
    "\n",
    "*   K Nearest Neighbor(KNN)\n",
    "*   Decision Tree\n",
    "*   Support Vector Machine\n",
    "*   Logistic Regression\n",
    "\n",
    "\\__ Notice:\\__\n",
    "\n",
    "*   You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n",
    "*   You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n",
    "*   You should include the code of the algorithm in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e93df54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b3b857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396bd903",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa302b5a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47abc5a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c608d949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc671cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
