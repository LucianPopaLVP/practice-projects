{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e1bf01f",
   "metadata": {},
   "source": [
    "# Classification with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574056dc",
   "metadata": {},
   "source": [
    "In this notebook we try to practice all the classification algorithms that we learned in this course.\n",
    "\n",
    "We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1719353",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7646fd",
   "metadata": {},
   "source": [
    "### About dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9ce0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "This dataset is about past loans. The Loan_train.csv data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db66503",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets download the dataset\n",
    "\n",
    "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56be8ae0",
   "metadata": {},
   "source": [
    "### Load Data From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3731cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aff45e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbf2d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['effective_date'] = pd.to_datetime(df['effective_date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8098e746",
   "metadata": {},
   "source": [
    "## Data visualization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d6c989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s see how many of each class is in our data set\n",
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418f1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "bins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68bd30a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(df.age.min(), df.age.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'age', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b11a040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2323d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at the day of the week people get the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c15fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = df['effective_date'].dt.dayofweek\n",
    "bins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b02342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that people who get the loan at the end of the week don't pay it off, so let's use Feature binarization to set a threshold value less than day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e625705",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812f8c51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical features to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7a543b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's look at gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f8cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ccc2352",
   "metadata": {},
   "outputs": [],
   "source": [
    "86 % of female pay there loans while only 73 % of males pay there loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8ee837",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's convert male to 0 and female to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b25634e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6c91e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "#### How about education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "458db301",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041e03a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Features before One Hot Encoding\n",
    "df[['Principal','terms','age','Gender','education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df43a1d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e978b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = df[['Principal','terms','age','Gender','weekend']]\n",
    "Feature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\n",
    "Feature.drop(['Master or Above'], axis = 1,inplace=True)\n",
    "Feature.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f98f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Selection\n",
    "X = Feature\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1546f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['loan_status'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77d7e6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c44fc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Standardization give data zero mean and unit variance (technically should be done after train test split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab6576e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8326ab8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060179af",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\n",
    "You should use the following algorithm:\n",
    "\n",
    "*   K Nearest Neighbor(KNN)\n",
    "*   Decision Tree\n",
    "*   Support Vector Machine\n",
    "*   Logistic Regression\n",
    "\n",
    "\\__ Notice:\\__\n",
    "\n",
    "*   You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n",
    "*   You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n",
    "*   You should include the code of the algorithm in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7985858b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266e7550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbor(KNN)\n",
    "\n",
    "Notice: You should find the best k to build the model with the best accuracy.\\\n",
    "**warning:** You should not use the **loan_test.csv** for finding the best k, however, you can split your train_loan.csv into train and test to find the best **k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65f37dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88db81e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "k = 3\n",
    "#Train Model and Predict  \n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "kNN_model\n",
    "knn_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87598129",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best k\n",
    "Ks=15\n",
    "mean_acc=np.zeros((Ks-1))\n",
    "std_acc=np.zeros((Ks-1))\n",
    "ConfustionMx=[];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    kNN_model = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    yhat = kNN_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mean_acc[n-1]=np.mean(yhat==y_test);\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480c35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model again, using k=5\n",
    "k = 5\n",
    "#Train Model and Predict  \n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "kNN_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5d9fe0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
