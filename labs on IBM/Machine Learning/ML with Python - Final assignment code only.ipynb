{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56069087",
   "metadata": {},
   "source": [
    "# Classification with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e476e0",
   "metadata": {},
   "source": [
    "In this notebook we try to practice all the classification algorithms that we learned in this course.\n",
    "\n",
    "We load a dataset using Pandas library, and apply the following algorithms, and find the best one for this specific dataset by accuracy evaluation methods.\n",
    "\n",
    "Lets first load required libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8067ef45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import NullFormatter\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.ticker as ticker\n",
    "from sklearn import preprocessing\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1d5153",
   "metadata": {},
   "source": [
    "### About dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "929ced8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "This dataset is about past loans. The Loan_train.csv data set includes details of 346 customers whose loan are already paid off or defaulted. It includes following fields:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "984a6221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets download the dataset\n",
    "\n",
    "!wget -O loan_train.csv https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/ML0101ENv3/labs/loan_train.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c6b0b1",
   "metadata": {},
   "source": [
    "### Load Data From CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f082ac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('loan_train.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618bbf67",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b614c1d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['due_date'] = pd.to_datetime(df['due_date'])\n",
    "df['effective_date'] = pd.to_datetime(df['effective_date'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46096351",
   "metadata": {},
   "source": [
    "## Data visualization and pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b80eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Letâ€™s see how many of each class is in our data set\n",
    "df['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d835c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "bins = np.linspace(df.Principal.min(), df.Principal.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'Principal', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6297abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(df.age.min(), df.age.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'age', bins=bins, ec=\"k\")\n",
    "\n",
    "g.axes[-1].legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1016a1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing:  Feature selection/extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5f1d2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Let's look at the day of the week people get the loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7573e2d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['dayofweek'] = df['effective_date'].dt.dayofweek\n",
    "bins = np.linspace(df.dayofweek.min(), df.dayofweek.max(), 10)\n",
    "g = sns.FacetGrid(df, col=\"Gender\", hue=\"loan_status\", palette=\"Set1\", col_wrap=2)\n",
    "g.map(plt.hist, 'dayofweek', bins=bins, ec=\"k\")\n",
    "g.axes[-1].legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e35be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We see that people who get the loan at the end of the week don't pay it off, so let's use Feature binarization to set a threshold value less than day 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb5375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weekend'] = df['dayofweek'].apply(lambda x: 1 if (x>3)  else 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13094b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Convert Categorical features to numerical values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafb5739",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's look at gender:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aa945a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Gender'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91c7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "86 % of female pay there loans while only 73 % of males pay there loan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f525743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Let's convert male to 0 and female to 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c699611c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Gender'].replace(to_replace=['male','female'], value=[0,1],inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afcb920",
   "metadata": {},
   "outputs": [],
   "source": [
    "## One Hot Encoding\n",
    "\n",
    "#### How about education?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab984ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['education'])['loan_status'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6374dcc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Features before One Hot Encoding\n",
    "df[['Principal','terms','age','Gender','education']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf9d45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Use one hot encoding technique to conver categorical varables to binary variables and append them to the feature Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c909b8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature = df[['Principal','terms','age','Gender','weekend']]\n",
    "Feature = pd.concat([Feature,pd.get_dummies(df['education'])], axis=1)\n",
    "Feature.drop(['Master or Above'], axis = 1,inplace=True)\n",
    "Feature.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bea02af",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Feature Selection\n",
    "X = Feature\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "129fbc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['loan_status'].values\n",
    "y[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1adddde1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Normalize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a982ab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data Standardization give data zero mean and unit variance (technically should be done after train test split)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4744fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= preprocessing.StandardScaler().fit(X).transform(X)\n",
    "X[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b832db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a29fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Now, it is your turn, use the training set to build an accurate model. Then use the test set to report the accuracy of the model\n",
    "You should use the following algorithm:\n",
    "\n",
    "*   K Nearest Neighbor(KNN)\n",
    "*   Decision Tree\n",
    "*   Support Vector Machine\n",
    "*   Logistic Regression\n",
    "\n",
    "\\__ Notice:\\__\n",
    "\n",
    "*   You can go above and change the pre-processing, feature selection, feature-extraction, and so on, to make a better model.\n",
    "*   You should use either scikit-learn, Scipy or Numpy libraries for developing the classification algorithms.\n",
    "*   You should include the code of the algorithm in the following cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6228baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and training sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=25)\n",
    "print ('Train set:', X_train.shape,  y_train.shape)\n",
    "print ('Test set:', X_test.shape,  y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9428d348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K Nearest Neighbor(KNN)\n",
    "\n",
    "Notice: You should find the best k to build the model with the best accuracy.\\\n",
    "**warning:** You should not use the **loan_test.csv** for finding the best k, however, you can split your train_loan.csv into train and test to find the best **k**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801b4fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4407b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling\n",
    "k = 3\n",
    "#Train Model and Predict  \n",
    "kNN_model = KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n",
    "kNN_model\n",
    "knn_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bea049",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding the best k\n",
    "Ks=15\n",
    "mean_acc=np.zeros((Ks-1))\n",
    "std_acc=np.zeros((Ks-1))\n",
    "ConfustionMx=[];\n",
    "for n in range(1,Ks):\n",
    "    \n",
    "    #Train Model and Predict  \n",
    "    kNN_model = KNeighborsClassifier(n_neighbors=n).fit(X_train,y_train)\n",
    "    yhat = kNN_model.predict(X_test)\n",
    "    \n",
    "    \n",
    "    mean_acc[n-1]=np.mean(yhat==y_test);\n",
    "    \n",
    "    std_acc[n-1]=np.std(yhat==y_test)/np.sqrt(yhat.shape[0])\n",
    "mean_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2054506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b204aa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
